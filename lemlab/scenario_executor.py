__author__ = "sdlumpp"
__credits__ = []
__license__ = ""
__maintainer__ = "sdlumpp"
__email__ = "sebastian.lumpp@tum.de"


import time
import json
import string
import shutil
import os
import multiprocessing as mp
from random import choice
from tqdm import tqdm
import pandas as pd
import feather as ft
import numpy as np
from ruamel.yaml import YAML
from lemlab.db_connection.db_connection import DatabaseConnection
from lemlab.agents import Prosumer
from lemlab.agents import Aggregator
from lemlab.agents import Retailer
import lemlab.lem.clearing_ex_ante as clearing_ex_ante
import lemlab.lem.settlement as lem_settlement
import warnings


class ScenarioExecutor:
    """
    This class takes a scenario as generated by ScenarioManager and executes the simulation.

    ...

    Attributes
    ----------
    path_scenario : str
        path to the previously generated scenario
    path_results : str
        path where simulation results should be saved
    t_now : int
        simulation "current time" pointer, UNIX timestamp
    step_counter: int
        simulation step counter, used to trigger functions that are not executed in every step
    db_conn_admin : DatabaseConnection
        database connection object used by the ScenarioExecutor object to perform admin tasks
    db_conn_user : DatabaseConnection
        database connection object passed to simulated market participants to perform non_admin tasks
    config: dictionary
        contains the simulation configuration parameters


    Public Methods
    -------
    __init__(path_scenario=None, path_results=None)
        initializer, takes input and output paths as params

    run()
        main functionality, sets up simulation and runs it according to the config yaml. In the case of real-time
        emulation, the emulation must be manually ended using end_execution

    end_execution()
        ends the running emulation, closes database connections and saves a snapshot of the database to disk. called
        automatically at the end of any full-speed simulation. Must be called manually to end a running
        real-time emulation.

    restart()s
        restarts a real time simulation previously ended with end_execution(). Useful for long term HiL tests where
        continuous deployment is desired. Please note that pausing for more than a few minutes is undesirable.

    export_database_snapshot()
        takes a database snapshot of a running simulation/emulation. Called automatically at the end of any simulation.
        Must be called manually if the current state of a real-time emulation is to be plotted using ScenarioAnalyzer
    """

    def __init__(self,
                 path_scenario: str = None,
                 path_results: str = None):
        """
        Initializer

        :param path_scenario: path pointing to scenario directory that is to be simulation
        :param path_results: path specifying the name and location of the results directory to be created

        :return None:
        """
        # set paths to input and output directories
        self.path_scenario = path_scenario
        self.path_results = path_results
        # initialize simulation "current time" pointer
        self.t_now = None
        # initialize simulation step counter, used for certain scheduling tasks
        self.step_counter = None
        # initialize database connection objects
        self.db_conn_admin = None
        self.db_conn_user = None
        self.config = None

    def run(self) -> None:
        """
        Sets up and runs the simulation according to the config yaml. In the case of real-time
        emulation, the emulation must be manually ended using end_execution()

       :return: None
        """
        self.__prepare_execution()

        self.__execute()

        self.__end_execution()

    def restart(self) -> None:
        """
        Restarts a real time simulation previously ended with end_execution(). Useful for long term HiL tests where
        continuous deployment is desired. Please note that pausing for more than a few minutes is undesirable.

        :return: None
        """
        # load config YAML into memory
        with open(f"{self.path_results}/config.yaml") as config_file:
            self.config = YAML().load(config_file)
        if self.config["simulation"]["rts"] is not True:
            print("Only real-time simulations can be restarted...")
            exit()

        with open(f"{self.path_results}/sim_info.json", "r") as read_file:
            dict_sim = json.load(read_file)

        if dict_sim["quit_sim"] is True:
            print("This simulation was previously manually ended. Are you sure you want to manually restart?")
            x = input("Press <y> to continue, any other key to abort... ")
            if x == "y":
                dict_sim["quit_sim"] = False
                with open(f"{self.path_results}/sim_info.json", "w+") as write_file:
                    json.dump(dict_sim, write_file)
            else:
                exit()

        self.t_now = round(time.time())
        # initialize step counter to 0
        self.step_counter = 0
        # setup database connections required
        self.db_conn_admin = DatabaseConnection(
            db_dict=self.config["db_connections"]["database_connection_admin"],
            lem_config=self.config["lem"])
        self.db_conn_user = DatabaseConnection(
            db_dict=self.config["db_connections"]["database_connection_user"],
            lem_config=self.config["lem"])

        self.__execute()

        self.__end_execution()

    def __end_execution(self):
        """
        Ends the running simulation, closes instances of DatabaseConnection and saves a snapshot of the database to
        disk. Called automatically at the end of any simulation.

        Calling end_execution() triggers __end_execution() for stopping real-time simulations.

        :param: None

        :return: None

        """
        self.export_database_snapshot()
        with open(f"{self.path_results}/sim_info.json", "r") as read_file:
            dict_sim = json.load(read_file)
        dict_sim["quit_sim"] = True
        with open(f"{self.path_results}/sim_info.json", "w+") as write_file:
            json.dump(dict_sim, write_file)

        self.db_conn_admin.end_connection()
        self.db_conn_user.end_connection()
        # exit()

    def end_execution(self):
        """
        Triggers a safe and controlled exit from a running real-time simulation. Saves a snapshot of the database to
        disk.

        Comment: to use this function for a running real-time emulation, the user should create a new ScenarioExecutor
                instance using the console, and call end_execution() on that instance.

        :return: None

        """
        with open(f"{self.path_results}/sim_info.json", "r") as read_file:
            dict_sim = json.load(read_file)
        dict_sim["quit_sim"] = True
        with open(f"{self.path_results}/sim_info.json", "w+") as write_file:
            json.dump(dict_sim, write_file)

    def export_database_snapshot(self) -> None:
        """
        Takes a database snapshot of a running simulation/emulation. Called automatically at the end of any simulation.
        Must be called manually if the current state of a real-time emulation is to be plotted using ScenarioAnalyzer

        Comment: to use this function for a running real-time emulation, the user should create a new ScenarioExecutor
                instance using the console, and call "end_execution" on that instance.
        """
        if self.db_conn_admin is None:
            with open(f"{self.path_results}/config.yaml") as config_file:
                config = YAML().load(config_file)

            self.db_conn_admin = DatabaseConnection(
                db_dict=config["db_connections"]["database_connection_admin"],
                lem_config=config["lem"])
        path_db_results = f"{self.path_results}/db_snapshot"
        # create folder if it doesn't exist, do not delete
        self.__create_folders([[path_db_results, False]])
        self.db_conn_admin.save_all_tables(path=path_db_results)

    # Private methods

    # simulation setup methods

    def __prepare_execution(self):
        """
        Takes an existing scenario generated using ScenarioManager and converts it into a simulation ready to be
        executed in the simulation results path.
        """
        # remove any existing simulation results in the desired path and create the new base results structure by
        # copying the scenario to be executed
        shutil.rmtree(self.path_results, ignore_errors=True)
        shutil.copytree(src=self.path_scenario,
                        dst=self.path_results)

        # load config YAML into memory
        with open(f"{self.path_results}/config.yaml") as config_file:
            self.config = YAML().load(config_file)

        logfile = open(f"{self.path_results}/log.txt", "w+")
        logfile.write("")
        logfile.close()

        # initialize step counter to 0
        self.step_counter = 0

        # set simulation time to current time if real time simulation is desired
        # else initialize according to config file
        if self.config["simulation"]["rts"] is True:
            self.t_now = round(time.time()) - 900*self.config["simulation"]["rts_start_steps"]
        else:
            # synthetic time for a simulation
            self.t_now = pd.Timestamp(self.config["simulation"]["sim_start"],
                                      tz=self.config["simulation"]["sim_start_tz"]).timestamp() - 60

        # setup database connections required
        self.db_conn_admin = DatabaseConnection(
            db_dict=self.config["db_connections"]["database_connection_admin"],
            lem_config=self.config["lem"])
        self.db_conn_user = DatabaseConnection(
            db_dict=self.config["db_connections"]["database_connection_user"],
            lem_config=self.config["lem"])

        # check whether a full or partial simulation is desired and delete agents accordingly
        if self.config["simulation"]["rts"] is True:
            if self.config["simulation"]["lem_active"] is False:
                # remove retailer if lem is not to be simulated
                shutil.rmtree(f"{self.path_results}/retailer")
            else:
                # else finalize setup
                self.__setup_lem()

            if self.config["simulation"]["agents_active"] is False:
                # remove prosumers and aggregator if agents are not to be simulated
                shutil.rmtree(f"{self.path_results}/prosumer")
                shutil.rmtree(f"{self.path_results}/aggregator")
            else:
                # else finalize setup
                self.__setup_agents()
        else:
            self.__setup_lem()
            self.__setup_agents()

        # as real time simulations must be gracefully exited, a flag file is created here
        # containing a "quit_sim" flag. This flag can be raised using the end_execution() method, triggering a
        # database snapshot and a graceful simulation exit. This file is created here.
        with open(f"{self.path_results}/sim_info.json", "w+") as write_file:
            json.dump({"quit_sim": False, "ts_delivery": None}, write_file)

    def __setup_agents(self, t_override=None) -> None:
        """
        Finalizes setup of agents before simulation begins.

        :param: None

        :return: None

        """
        t_setup = t_override if t_override is not None else self.t_now
        ts_delivery_first = int((t_setup - t_setup % 900 + 900))

        id_len = 10
        null_id = "0" * id_len
        euro_kwh_to_sigma_wh = self.db_conn_admin.db_param.EURO_TO_SIGMA / 1000

        list_prosumers = os.listdir(self.path_results + "/prosumer")
        # for each prosumer, complete setup
        for prosumer in list_prosumers:
            # load configurations for each prosumer
            path_prosumer = f"{self.path_results}/prosumer/{prosumer}/"
            with open(f"{path_prosumer}/config_account.json", "r") as read_file:
                prosumer_config = json.load(read_file)
            with open(f"{path_prosumer}/config_plants.json", "r") as read_file:
                plant_config = json.load(read_file)
            # if there is no active ex-ante market, no market agent is required.
            if len(self.config["lem"]["types_clearing_ex_ante"]) == 0:
                prosumer_config["market_agent"] = None

            # register user in DB

            dict_user = {
                self.db_conn_admin.db_param.ID_USER:                    [prosumer],
                self.db_conn_admin.db_param.BALANCE_ACCOUNT:            [0],
                self.db_conn_admin.db_param.T_UPDATE_BALANCE:           [t_setup],
                self.db_conn_admin.db_param.PRICE_ENERGY_BID_MAX:       [prosumer_config["ma_bid_max"]
                                                                         * euro_kwh_to_sigma_wh],
                self.db_conn_admin.db_param.PRICE_ENERGY_OFFER_MIN:     [prosumer_config["ma_offer_min"]
                                                                         * euro_kwh_to_sigma_wh],
                self.db_conn_admin.db_param.PREFERENCE_QUALITY:         [prosumer_config["ma_preference_quality"]],
                self.db_conn_admin.db_param.PREMIUM_PREFERENCE_QUALITY:
                    [prosumer_config["ma_premium_preference_quality"]],
                self.db_conn_admin.db_param.STRATEGY_MARKET_AGENT:      [prosumer_config["ma_strategy"]],
                self.db_conn_admin.db_param.ID_MARKET_AGENT:            [prosumer_config["id_market_agent"]],
                self.db_conn_admin.db_param.HORIZON_TRADING:            [prosumer_config["ma_horizon"]],
                self.db_conn_admin.db_param.TS_DELIVERY_FIRST:          [ts_delivery_first],
                self.db_conn_admin.db_param.TS_DELIVERY_LAST:           [(2 ** 31) - 1]}
            self.db_conn_admin.register_user(pd.DataFrame().from_dict(dict_user))

            # register main meter in DB

            dict_meter = {
                self.db_conn_admin.db_param.ID_METER:          [prosumer_config["id_meter_grid"]],
                self.db_conn_admin.db_param.ID_USER:           [prosumer],
                self.db_conn_admin.db_param.ID_METER_SUPER:    [null_id],
                self.db_conn_admin.db_param.TYPE_METER:        [self.config["lem"]["types_meter"][4]],
                self.db_conn_admin.db_param.ID_AGGREGATOR:     [null_id],
                self.db_conn_admin.db_param.QUALITY_ENERGY:    ["na"],
                self.db_conn_admin.db_param.TS_DELIVERY_FIRST: [ts_delivery_first],
                self.db_conn_admin.db_param.TS_DELIVERY_LAST:  [2 ** 31 - 1],
                self.db_conn_admin.db_param.INFO_ADDITIONAL:   ["main meter"]}
            self.db_conn_admin.register_meter(pd.DataFrame().from_dict(dict_meter))

            # register each plant in the database
            for plant in prosumer_config["list_plants"]:
                if plant_config[plant].get("fcast") == "aggregator":
                    agg_id = self.config["aggregator"]["id_user"]
                else:
                    agg_id = null_id

                dict_meter = {
                    self.db_conn_admin.db_param.ID_METER: [plant],
                    self.db_conn_admin.db_param.ID_USER: [prosumer],
                    self.db_conn_admin.db_param.TYPE_METER: [self.config["lem"]["types_meter"][0]],
                    self.db_conn_admin.db_param.ID_METER_SUPER: [prosumer_config["id_meter_grid"]],
                    self.db_conn_admin.db_param.ID_AGGREGATOR: [agg_id],
                    self.db_conn_admin.db_param.QUALITY_ENERGY: [plant_config[plant].get("quality", "na")],
                    self.db_conn_admin.db_param.TS_DELIVERY_FIRST: [ts_delivery_first],
                    self.db_conn_admin.db_param.TS_DELIVERY_LAST: [2 ** 31 - 1],
                    self.db_conn_admin.db_param.INFO_ADDITIONAL: [plant_config[plant].get("type")]}
                if plant_config[plant].get("has_submeter") is False:
                    dict_meter[self.db_conn_admin.db_param.ID_METER] = [self.__gen_rand_id(10)]
                    dict_meter[self.db_conn_admin.db_param.TYPE_METER] = [self.config["lem"]["types_meter"][1]]
                    if plant_config[plant].get("type") == "hh":
                        dict_meter[self.db_conn_admin.db_param.INFO_ADDITIONAL] = ["residual load"]
                    else:
                        dict_meter[self.db_conn_admin.db_param.INFO_ADDITIONAL] = \
                            [f"{plant_config[plant].get('type')}"]
                self.db_conn_admin.register_meter(pd.DataFrame().from_dict(dict_meter))

            # create a local log for all energy flows, log_ems.ft
            list_columns = ["timestamp", f"gr_{prosumer_config['id_meter_grid']}"]
            for plant in prosumer_config["list_plants"]:
                list_columns.append(f"{plant_config[plant]['type']}_{plant}")

            ft.write_dataframe(pd.DataFrame(columns=list_columns), f"{path_prosumer}/log_ems.ft")

            # create a meter readings buffer file
            # all meter readings are first buffered to this file
            # some meter readings are delayed if this configuration is active
            ft.write_dataframe(pd.DataFrame(columns=["t_reading",
                                                     "energy_in_cum",
                                                     "energy_out_cum",
                                                     "id_meter",
                                                     "t_send"]),
                               f"{path_prosumer}/buffer_meter_readings.ft")

            # create file to store real time controller set points between steps
            self.__create_target_grid_power(prosumer_config=prosumer_config,
                                            plant_config=plant_config,
                                            ts_delivery_first=ts_delivery_first - 900)

            # set up initial price history
            index = range(ts_delivery_first - 900 * prosumer_config["mpc_horizon"]*2,
                          ts_delivery_first,
                          900)

            init_price_data = np.zeros(shape=(len(index), 7))
            init_price_data[:, 0] = index
            init_price_data[:, 1] = (self.config["retailer"]["price_sell"] + self.config["retailer"]["price_buy"]) / 2
            init_price_data[:, 2] = 0
            init_price_data[:, 3] = self.config["lem"]["price_energy_balancing_positive"]
            init_price_data[:, 4] = self.config["lem"]["price_energy_balancing_negative"]
            init_price_data[:, 5] = self.config["lem"]["price_energy_levies_positive"]
            init_price_data[:, 6] = self.config["lem"]["price_energy_levies_negative"]

            ft.write_dataframe(pd.DataFrame(init_price_data,
                                            columns=["timestamp",
                                                     "weighted_average_price",
                                                     "total_energy_traded",
                                                     "price_energy_balancing_positive",
                                                     "price_energy_balancing_negative",
                                                     "price_energy_levies_positive",
                                                     "price_energy_levies_negative"]),
                               f"{path_prosumer}/price_history.ft")

        # aggregator setup
        if self.config["aggregator"]["active"]:

            path_agg = f"{self.path_results}/aggregator/"
            with open(f"{path_agg}/config_account.json", "r") as read_file:
                config_agg = json.load(read_file)

            euro_kwh_to_sigma_wh = self.db_conn_admin.db_param.EURO_TO_SIGMA / 1000
            # register aggregator in database
            dict_user = {
                self.db_conn_admin.db_param.ID_USER:                    [config_agg["id_user"]],
                self.db_conn_admin.db_param.BALANCE_ACCOUNT:            [0],
                self.db_conn_admin.db_param.T_UPDATE_BALANCE:           [t_setup],
                self.db_conn_admin.db_param.PRICE_ENERGY_BID_MAX:       [self.config["retailer"]["price_sell"]
                                                                         * euro_kwh_to_sigma_wh],
                self.db_conn_admin.db_param.PRICE_ENERGY_OFFER_MIN:     [self.config["retailer"]["price_buy"]
                                                                         * euro_kwh_to_sigma_wh],
                self.db_conn_admin.db_param.PREFERENCE_QUALITY:         [config_agg["preference_quality"]],
                self.db_conn_admin.db_param.PREMIUM_PREFERENCE_QUALITY: [config_agg["premium_preference_quality"]],
                self.db_conn_admin.db_param.STRATEGY_MARKET_AGENT:      [config_agg["ma_strategy"]],
                self.db_conn_admin.db_param.ID_MARKET_AGENT:            [config_agg["id_user"]],
                self.db_conn_admin.db_param.HORIZON_TRADING:            [config_agg["ma_horizon"]],
                self.db_conn_admin.db_param.TS_DELIVERY_FIRST:          [ts_delivery_first],
                self.db_conn_admin.db_param.TS_DELIVERY_LAST:           [(2 ** 31) - 1]}

            self.db_conn_admin.register_user(pd.DataFrame().from_dict(dict_user))

    def __setup_lem(self, t_override=None) -> None:
        """
        Finalize LEM lem set up by initializing db and registering retailer account

        :param: None

        :return: None
        """
        t_setup = t_override if t_override is not None else self.t_now

        # initialise database by wiping existing database and resetting tables
        self.db_conn_admin.init_db(clear_tables=True,
                                   reformat_tables=True)

        # initialize the settlement status database
        # by setting the last delivery timestep before simulation begin to "settled"
        dict_status = {
            self.db_conn_admin.db_param.TS_DELIVERY: [t_setup - t_setup % 900],
            self.db_conn_admin.db_param.STATUS_METER_READINGS_PROCESSED: [1],
            self.db_conn_admin.db_param.STATUS_SETTLEMENT_COMPLETE: [1]
            }
        self.db_conn_admin.set_status_settlement(pd.DataFrame().from_dict(dict_status))

        # by setting the last settlement prices

        lem_settlement.set_prices_settlement(db_obj=self.db_conn_admin,
                                             path_simulation=self.path_results,
                                             list_ts_delivery=[t_setup - t_setup % 900])

        # retailer setup

        ts_delivery_first = int((t_setup - t_setup % 900 + 900))

        euro_kwh_to_sigma_wh = self.db_conn_admin.db_param.EURO_TO_SIGMA / 1000

        # register retailer as participant
        dict_user = {
            self.db_conn_admin.db_param.ID_USER: [self.config["retailer"]["id_user"]],
            self.db_conn_admin.db_param.BALANCE_ACCOUNT: [0],
            self.db_conn_admin.db_param.T_UPDATE_BALANCE: [self.t_now],
            self.db_conn_admin.db_param.PRICE_ENERGY_BID_MAX: [self.config["retailer"]["price_sell"]
                                                               * euro_kwh_to_sigma_wh],
            self.db_conn_admin.db_param.PRICE_ENERGY_OFFER_MIN: [self.config["retailer"]["price_buy"]
                                                                 * euro_kwh_to_sigma_wh],
            self.db_conn_admin.db_param.PREFERENCE_QUALITY: ["na"],
            self.db_conn_admin.db_param.PREMIUM_PREFERENCE_QUALITY: [0],
            self.db_conn_admin.db_param.STRATEGY_MARKET_AGENT: ["retailer"],
            self.db_conn_admin.db_param.ID_MARKET_AGENT: [self.config["retailer"]["id_user"]],
            self.db_conn_admin.db_param.HORIZON_TRADING: [1],
            self.db_conn_admin.db_param.TS_DELIVERY_FIRST: [ts_delivery_first],
            self.db_conn_admin.db_param.TS_DELIVERY_LAST: [(2**31)-1]}
        self.db_conn_admin.register_user(pd.DataFrame().from_dict(dict_user))

    # simulation execution
    def __execute(self):
        path_weather = f"{self.path_results}/weather/weather.ft"
        # choose execution mode: "real-time" or normal simulation
        if self.config["simulation"]["rts"] is True:
            with open(f"{self.path_results}/sim_info.json", "r") as read_file:
                dict_sim = json.load(read_file)

            if dict_sim["ts_delivery"] is not None:
                ts_delivery_start = dict_sim["ts_delivery"]
            else:
                ts_delivery_start = self.t_now - self.t_now % 900 + 900

            # simulation time range is set here. The simulation runs from now until the end of UNIX time, unless stopped
            # by the end_execution() method
            ts_delivery_end = (2 ** 31) - 1
            ts_delivery_current = ts_delivery_start
            # configure progress bar
            pbar = tqdm(bar_format="{desc}")
            # endless while loop, unless ended by the quit_sim flag through end_execution()
            while ts_delivery_current <= ts_delivery_end:
                # update progress bar
                with open(f"{self.path_results}/sim_info.json", "r") as read_file:
                    dict_sim = json.load(read_file)
                dict_sim["ts_delivery"] = ts_delivery_current
                with open(f"{self.path_results}/sim_info.json", "w+") as write_file:
                    json.dump(dict_sim, write_file)

                self.__wait_for_time(target_time=ts_delivery_current + 60,
                                     progress_bar=pbar,
                                     reason=f" to execute market agents... ")

                self.t_now = round(time.time())
                if self.t_now > ts_delivery_current + 900:
                    self.t_now = ts_delivery_current + 60

                # do pre clearing things for prosumers and aggregators
                self.__step_prosumers_pre()
                self.__step_aggregator_pre()
                self.__step_retailer_pre()

                self.__wait_for_time(target_time=ts_delivery_current + 10*60,
                                     progress_bar=pbar,
                                     reason=f" to clear and settle the market... ")

                # at five minutes before delivery:
                # 1: if ex_ante, clear the market, then settle the previous steps
                # 2: if ex_post, settle previous steps

                self.t_now = round(time.time())
                if self.t_now > ts_delivery_current + 900:
                    self.t_now = ts_delivery_current + 10*60

                pbar.set_description_str(
                    f"{pd.Timestamp(self.t_now, unit='s', tz=self.config['simulation']['sim_start_tz'])}:"
                    f" market clearing and settlement")

                self.__step_lem()

                pbar.set_description_str(
                    f"{pd.Timestamp(self.t_now, unit='s', tz=self.config['simulation']['sim_start_tz'])}:"
                    f" agents retrieving market results")
                self.__step_prosumers_post()

                with open(f"{self.path_results}/sim_info.json", "r") as read_file:
                    dict_sim = json.load(read_file)
                dict_sim["ts_delivery"] = ts_delivery_current
                with open(f"{self.path_results}/sim_info.json", "w+") as write_file:
                    json.dump(dict_sim, write_file)

                ts_delivery_current += 900
                self.step_counter += 1

        elif self.config["simulation"]["rts"] is not True:
            # simulation time range is set here, as defined in the config YAML

            ts_delivery_start = pd.Timestamp(self.config["simulation"]["sim_start"],
                                             tz=self.config["simulation"]["sim_start_tz"]).timestamp()
            ts_delivery_end = ts_delivery_start + self.config["simulation"]["sim_length"] * 86400
            ts_delivery_current = int(ts_delivery_start)

            # configure progress bar
            str_len = 42
            simulation_length = int((ts_delivery_end - ts_delivery_start) / 900 + 1)
            pbar = tqdm(range(simulation_length), total=simulation_length)

            # set up multiprocessing pool for prosumer functionality
            # pre-clearing activity is computationally intensive, as it contains utilities and optimization
            with mp.Pool(initializer=_par_step_prosumers_init,
                         initargs=(_par_step_prosumers_pre,
                                   self.config,
                                   path_weather)
                         ) as pool:
                # main simulation loop, step from ts_delivery start to end
                while ts_delivery_current <= ts_delivery_end:
                    # at one minute past the quarter hour:
                    self.t_now = ts_delivery_current + 60
                    # set new label on progress bar
                    str_time = \
                        f"Simulating timestep #{self.step_counter} at " \
                        f"{pd.Timestamp(ts_delivery_current, unit='s', tz=self.config['simulation']['sim_start_tz'])}"
                    pbar.set_description(f"{str_time}: {'Forecasting and posting by market agents'.ljust(str_len)}")

                    # perform pre-clearing activities for prosumers, aggregators, retailer
                    # pre-clearing includes real-time controllers, logging of meter values, utilities,
                    # model predictive control and posting bids to the market
                    pool.map(_par_step_prosumers_pre,
                             self.__gen_par_step_prosumers_pre_input())
                    self.__step_aggregator_pre()
                    self.__step_retailer_pre()

                    self.t_now = ts_delivery_current + 900 - 5 * 60
                    # at five minutes before the end of the quarter hour:
                    # 1: market clearing (if ex-ante market) and market settlement
                    pbar.set_description(f"{str_time}: {'Market clearing and settlement'.ljust(str_len)}")
                    self.__step_lem()
                    # 2: prosumers check market results
                    pbar.set_description(f"{str_time}: {'Checking of market results'.ljust(str_len)}")
                    pbar.update()
                    self.__step_prosumers_post()
                    # increment ts_delivery and step_counter
                    ts_delivery_current += 900
                    self.step_counter += 1
                    # end of main while loop
            # after main simulation completed
            pbar.set_description("Computation finished and results saved")  # update progress bar
            pbar.close()        # close progress bar
            pool.close()        # close parallel pool
        else:
            print("Error: parameter 'simulation' 'real-time' must be True or False")

    # agent pre-clearing activities

    def __step_retailer_pre(self, clear_positions=False):
        """
        Performs pre-clearing activities for all retailers in the simulation.
        New instances are instantiated and retailer.pre_clearing_activity() is
        executed for each.

        :param: None

        :return: None
        """
        list_active_retailers = self.__get_active_retailers()
        for retailer in list_active_retailers:
            retailer.pre_clearing_activity(db_obj=self.db_conn_user,
                                           clear_positions=clear_positions)

    def __step_aggregator_pre(self, clear_positions=False):
        """
        Performs pre-clearing activities for all aggregators in the simulation.
        New instances are instantiated and Aggregator.pre_clearing_activity() is
        executed for each.

        :param: None

        :return: None
        """
        list_aggregators = self.__get_active_aggregators()
        for aggregator in list_aggregators:
            aggregator.pre_clearing_activity(
                db_obj=self.db_conn_user,
                clear_positions=clear_positions)

    def __step_prosumers_pre(self, clear_positions=False):
        """
        Performs pre-clearing activities for all prosumers in the simulation.
        New instances are instantiated and Prosumer.pre_clearing_activity() is
        executed for each.

        Used for real-time emulations only, as simulations are conducted using
        scenario_executor._par_step_prosumers_pre().

        :param: None

        :return: None
        """
        list_prosumers = self.__get_active_prosumers()
        for prosumer in list_prosumers:
            prosumer.pre_clearing_activity(db_obj=self.db_conn_user,
                                           clear_positions=clear_positions)

    def __gen_par_step_prosumers_pre_input(self):
        """
        Prepares a list of inputs for scenario_executor._par_step_prosumers_pre().
        Performs pre-clearing activities for all prosumers in the simulation.
        New instances are instantiated and prosumer.pre_clearing_activity() is
        executed for each.

        :param: None

        :return: list of dicts: A dict for each prosumer containing:
                                path prosumer -- str - a path to the prosumer's directory
                                t_now         -- int - the current simulation time to be used by the parallel process
        """
        # get list all prosumers in the simulation
        if self.config["simulation"]["agents_active"]:
            list_paths_prosumers = os.listdir(self.path_results + "/prosumer")
        else:
            list_paths_prosumers = []

        list_par_inputs = []
        # generate input list for parallel processing of prosumers
        for i, _ in enumerate(list_paths_prosumers):
            list_par_inputs.append({"path_prosumer": self.path_results + "/prosumer/" + list_paths_prosumers[i],
                                    "t_now": self.t_now})
        return list_par_inputs

    # agent-post-clearing activities

    def __step_prosumers_post(self) -> None:
        """
        Performs post-clearing activities for all prosumers in the simulation.
        New instances are instantiated and Prosumer.post_clearing_activity() is
        executed for each.

        :param: None

        :return: None
        """
        for prosumer in self.__get_active_prosumers():
            prosumer.post_clearing_activity(db_obj=self.db_conn_user)

    # step lem

    def __step_lem(self) -> None:
        """
        Performs market clearing and market settlement according to the simulation config YAML.

        All market types listed in the config are calculated and cleared. If no ex-ante markets
        are configured, the first ex-post pricing and clearing will be used for settlement.

        Otherwise, the first ex-ante clearing and price types will be used for settlement.

        :param: None

        :return: None
        """
        # initialize new settlement status for current ts_delivery
        dict_status = {
            self.db_conn_admin.db_param.TS_DELIVERY: [self.t_now - self.t_now % 900],
            self.db_conn_admin.db_param.STATUS_METER_READINGS_PROCESSED: [0],
            self.db_conn_admin.db_param.STATUS_SETTLEMENT_COMPLETE: [0]
        }
        self.db_conn_admin.set_status_settlement(pd.DataFrame().from_dict(dict_status))

        # check for which ts_delivery ALL meter readings have been logged, calculate energy deltas for each meter
        # label processed steps in status_settlement
        lem_settlement.update_complete_meter_readings(db_obj=self.db_conn_admin)

        # set settlement prices for current simulation ts_delivery in database, as agents need these for their naive
        # forecasts
        # TODO: adjust agent forecasts so this step is unnecessary
        # TODO: add option of posting settlement prices in advance, useful for time-varying tariffs
        lem_settlement.set_prices_settlement(db_obj=self.db_conn_admin,
                                             path_simulation=self.path_results,
                                             list_ts_delivery=[self.t_now - self.t_now % 900])
        # generate list of ts_delivery that are ready to be settled (i.e. (his means meter readings have been processed)
        list_ts_delivery_ready = lem_settlement.get_list_ts_delivery_ready(db_obj=self.db_conn_admin)
        # in some simulations, some plant have no physical meters. Their power flow must be implicitly calculated and
        # assigned to a virtual meter.

        # if ex-ante market selected, clear market
        if self.config["lem"]["types_clearing_ex_ante"]:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                clearing_ex_ante.market_clearing(db_obj=self.db_conn_admin,
                                                 config_lem=self.config["lem"],
                                                 t_override=self.t_now)
        # if ex-post markets are to be calculated, this is done here
        if self.config["lem"]["types_clearing_ex_post"]:
            lem_settlement.set_community_price(db_obj=self.db_conn_admin,
                                               path_simulation=self.path_results,
                                               lem_config=self.config["lem"],
                                               list_ts_delivery=list_ts_delivery_ready)

        # final transaction settlement is performed now
        # only one market can be settled. This is the first ex-ante market listed,
        # if none is listed, the first ex-post is chosen
        if self.config["lem"]["types_clearing_ex_ante"]:
            # determine balancing energy flows
            lem_settlement.determine_balancing_energy(db_obj=self.db_conn_admin,
                                                      list_ts_delivery=list_ts_delivery_ready)
            # settle balancing energy costs with each user, trading costs were cleared in clearing_ex_ante.py
            lem_settlement.update_balance_balancing_costs(db_obj=self.db_conn_admin,
                                                          list_ts_delivery=list_ts_delivery_ready,
                                                          lem_config=self.config["lem"],
                                                          t_now=self.t_now,
                                                          id_retailer=self.config["retailer"]["id_user"])
        else:
            lem_settlement.update_balance_ex_post(db_obj=self.db_conn_admin,
                                                  id_retailer=self.config["retailer"]["id_user"],
                                                  lem_config=self.config["lem"],
                                                  list_ts_delivery=list_ts_delivery_ready,
                                                  t_now=self.t_now)
        # levy costs are determined based on
        # settle levy costs with each user
        lem_settlement.update_balance_levies(db_obj=self.db_conn_admin,
                                             list_ts_delivery=list_ts_delivery_ready,
                                             lem_config=self.config["lem"],
                                             t_now=self.t_now,
                                             id_retailer=self.config["retailer"]["id_user"])

        # initialize new settlement status for current ts_delivery
        for ts_d in list_ts_delivery_ready:
            dict_status = {
                self.db_conn_admin.db_param.TS_DELIVERY: [ts_d],
                self.db_conn_admin.db_param.STATUS_METER_READINGS_PROCESSED: [1],
                self.db_conn_admin.db_param.STATUS_SETTLEMENT_COMPLETE: [1]
            }
            self.db_conn_admin.set_status_settlement(pd.DataFrame().from_dict(dict_status))

    # auxiliary methods

    def __wait_for_time(self, target_time, progress_bar, reason, offset=0):
        """
        Waits for a target time before allowing the simulation to continue. Regularly updates the progress bar while
        waiting.

        If offset is set, we wait for a target time minus the offset. This is for real-time emulations using historical
        data.

        Checks the sim_info.json file to see whether user decided to end the simulation using end_execution()

        Wait message: Waiting for {target time}:  {reason}

        :param: target_time, int, unix timestamp to be waited for
        :param: progress_bar, tqdm instance, progress bar to be updated
        :param: reason: str, reason we are waiting
        :param: offset: int, unix timestamp offset

        :return: None
        """
        # determine current (offset) time
        t_now = round(time.time()) - offset
        # wait for the target time
        while t_now < target_time:
            time.sleep(1)                           # only check time every 5 seconds
            t_now = round(time.time()) - offset     # determine current (offset) time
            # update progress bar description
            msg = f"Waiting for {pd.Timestamp(target_time, unit='s', tz=self.config['simulation']['sim_start_tz'])}"
            progress_bar.set_description_str(f"{msg}: {reason}")
            # if user ended the simulation using end_execution()
            with open(f"{self.path_results}/sim_info.json", "r") as read_file:
                dict_sim = json.load(read_file)
            if dict_sim["quit_sim"] is True:
                progress_bar.set_description_str("Exiting simulation and saving results")
                progress_bar.close()
                self.__end_execution()

    def __get_active_prosumers(self) -> list:
        """
        Returns list of active prosumers in the simulation.

        :param: None

        :return: list, instances of Prosumer class
        """
        if self.config["simulation"]["agents_active"]:
            list_prosumers = os.listdir(self.path_results + "/prosumer")
        else:
            list_prosumers = []
        list_prosumer_obj = []
        for prosumer in list_prosumers:
            list_prosumer_obj.append(Prosumer(path=f"{self.path_results}/prosumer/{prosumer}",
                                              t_override=self.t_now))
        return list_prosumer_obj

    def __get_active_aggregators(self) -> list:
        """
        Returns list of active aggregators in the simulation.

        :param: None

        :return: list, instances of Aggregator class
        """
        list_aggregator_obj = []
        if self.config["simulation"]["agents_active"] and self.config["aggregator"]["active"]:
            list_aggregator_obj.append(Aggregator(path=f"{self.path_results}/aggregator/",
                                                  t_override=self.t_now))
        return list_aggregator_obj

    def __get_active_retailers(self) -> list:
        """
        Returns list of active retailers in the simulation.

        :param: None

        :return: list, instances of retailer class
        """

        list_retailer_obj = []
        if self.config["simulation"]["lem_active"] is True:
            list_retailer_obj.append(Retailer(path=f"{self.path_results}/retailer/",
                                              t_override=self.t_now))
        return list_retailer_obj

    def __create_target_grid_power(self, prosumer_config, plant_config, ts_delivery_first):
        """
        Creates a file in the given prosumer's directory for real time controller set points to be stored
        between simulation steps.

        :param: None

        :return: None
        """

        columns = ["timestamp", f"power_{prosumer_config['id_meter_grid']}"]
        for plant in prosumer_config["list_plants"]:
            if plant_config[plant].get("type") == "ev":
                columns.append(f"power_{plant}")
                columns.append(f"soc_min_{plant}")
            if plant_config[plant].get("type") == "bat":
                columns.append(f"power_{plant}")

        index = range(ts_delivery_first,
                      ts_delivery_first + 900 * prosumer_config["mpc_horizon"],
                      900)

        init_data = np.zeros(shape=(len(index), len(columns)),
                             dtype=int)
        init_data[:, 0] = index

        df_target_grid_power = pd.DataFrame(init_data, columns=columns).set_index("timestamp")

        path_prosumer = f"{self.path_results}/prosumer/{prosumer_config['id_user']}/"

        ft.write_dataframe(df_target_grid_power.reset_index(),
                           f"{path_prosumer}/target_grid_power.ft")

    def __create_folders(self, list_paths):
        for path, delete_flag in list_paths:
            if os.path.isdir(path):
                try:
                    if delete_flag:
                        self.__del_file_contents(path)
                except FileNotFoundError:
                    pass
            else:
                os.mkdir(path)
        time.sleep(0.1)

    @staticmethod
    def __del_file_contents(path):
        """Deletes all contents within the specified path."""
        for root, directories, files in os.walk(path):
            for file in files:
                os.unlink(os.path.join(root, file))
            for directory in directories:
                shutil.rmtree(os.path.join(root, directory))

    @staticmethod
    def __gen_rand_id(length: int):
        """Generates a random combination of ascii characters and digits of specified length."""
        characters = string.ascii_lowercase + string.digits * 3
        return ''.join(choice(characters) for _ in range(length))


# parallel functions need to be defined outside of the class to work

def _par_step_prosumers_init(func, config, path_weather):
    """
    Initializes DatabaseConnection instances for par_step_prosumer_pre processes.

    Database connections cannot be serialized, therefore a DatabaseConnection instance is attached to each process

    :param func: function to which the DatabaseConnection instance is to be attached

    :param db_dict: dict, DatabaseConnection parameters from the config YAML

    :param lem_config: dict, LEM config dict required to create a DatabaseConnection object

    """
    # initialize each multiprocessing worker with a database connection
    func.db_conn = DatabaseConnection(db_dict=config["db_connections"]["database_connection_user"],
                                      lem_config=config["lem"])
    # each multiprocessing worker gets a copy of the weather file for the simulation,
    # as every worker needs to regularly access the same read-only file

    df_weather = ft.read_dataframe(path_weather)
    df_weather = df_weather.astype({'ts_delivery_current': 'int', 'ts_delivery_fcast': 'int'})
    df_weather.set_index(["ts_delivery_current", "ts_delivery_fcast"], inplace=True)

    t_first = pd.Timestamp(config["simulation"]["sim_start"],
                           tz=config["simulation"]["sim_start_tz"]).timestamp() - 60
    t_last = t_first + config["simulation"]["sim_length"] * 86400 + 86400
    t_first_history = t_first - 100 * 86400

    # slice weather data into historical data for forecast algorithm training (100 days)
    # as well as perfect forecasting
    df_weather_history = df_weather.loc[(slice(t_first_history, t_last + 3 * 86400), slice(None))]
    df_weather_history = \
        df_weather_history[df_weather_history.index.get_level_values(level=0)
                           == df_weather_history.index.get_level_values(level=1)]
    # slice weather forecasts for required simulation period from full weather file
    df_weather_fcast = df_weather.loc[(slice(t_first - 900, t_last + 1), slice(None))]

    func.df_weather_history = df_weather_history
    func.df_weather_fcast = df_weather_fcast


def _par_step_prosumers_pre(list_info_prosumers):
    """
    Performs pre-clearing activities for all prosumers in the simulation.
    New instances are instantiated and Prosumer.pre_clearing_activity() is
    executed for each.

    Used for non-real-time simulations only, as rea-time simulations are conducted using
    scenario_executor.__step_prosumers_pre().

    :param: None

    :return: None
    """
    prosumer = Prosumer(path=list_info_prosumers["path_prosumer"],
                        t_override=list_info_prosumers["t_now"],
                        df_weather_history=_par_step_prosumers_pre.df_weather_history,
                        df_weather_fcast=_par_step_prosumers_pre.df_weather_fcast,
                        tf_import=True)

    prosumer.pre_clearing_activity(db_obj=_par_step_prosumers_pre.db_conn)
